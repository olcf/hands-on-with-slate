# Debugging with More Information

## Exercise: Unschedulable Pod

One of the first steps when a Pod is created is for the scheduler to assign it to a
node but if the scheduler is unable to do that the Pod appears to just hang and never
run. This can be confusing for the user because in most cases the Pod (or Deployment)
was created successfully.

First we will create our bare pod:

```bash
$ oc apply -f pod_schedule.yaml
pod/test-pod created
```

Next let's get a list of Pods in the Namespace:

```bash
$ oc get pods
NAME       READY   STATUS    RESTARTS   AGE
test-pod   0/1     Pending   0          42s
```

From the overview of Pods we can see that the pod seems to be stuck in the `Pending` state
and the one container in the Pod is not ready `0/1`. In previous modules we showed how to
use `oc describe` to get more information but this time we will be using `oc get` again
but to get Event objects.

> Events are generated by components in the cluster to help to understand who is operating on what

We are using two extra arguments to `oc get`:

| Argument | Definition |
| --- | --- |
| --sort-by=.metadata.creationTimestamp | Sort the event objects by creation timestamp. Generally not needed on `get` calls but Events are uniquely chronological |
| --field-selector=involvedObject.name=test-pod | Events can be linked another object in the cluster that they are referring to and we can use the field selector to only get the Events we want to see right now |

```bash
$ oc get events --sort-by=.metadata.creationTimestamp --field-selector=involvedObject.name=test-pod
LAST SEEN   TYPE      REASON             OBJECT                  MESSAGE
3m4s        Warning   FailedScheduling   pod/test-pod   0/40 nodes are available: 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 37 node(s) didn't match Pod's node affinity.
105s        Warning   FailedScheduling   pod/test-pod   0/40 nodes are available: 3 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 37 node(s) didn't match Pod's node affinity.
```

We can see under the reason field why our pod is stuck in Pending: **FailedScheduling** but
the message is a bit cryptic. It is saying that it looked at scheduling the Pod onto 40 nodes
but none met the criteria for scheduling and then the scheduler lists the reasons it kicked
nodes out of the total pool of schedulable nodes for the Pod. Three nodes had a scheduling
taint that wasn't tolerated by the Pod and thirty seven nodes did not match the Pod's
"node affinity" and then we are at zero available nodes.

If we check our Pod's spec we see more of the story:

```yaml
spec:
  nodeSelector:
    foo: bar-does-not-exist
```

We are attempting to schedule onto nodes that have a label of `foo: bar-does-not-exist` which
no nodes have so the scheduler cannot satisify this requirement for node affinity and fails
to schedule the workload.

```diff
--- pod_schedule.yaml
+++ pod_image.yaml
@@ -1,12 +1,10 @@
 apiVersion: v1
 kind: Pod
 metadata:
-  name: test-pod
+  name: test-pod-2
   labels:
     tutorial: debugging
 spec:
-  nodeSelector:
-    foo: bar-does-not-exist
   containers:
     - name: test-pod
       image: "cents:7"
```

We can delete this Pod and create the another:

```bash
oc delete -f pod_schedule.yaml
oc apply -f pod_image.yaml
```

If we use `oc get`:

```bash
$ oc get pods
NAME         READY   STATUS             RESTARTS   AGE
test-pod-2   0/1     ImagePullBackOff   0          49s
```

We see that our Pod is either in **ErrImagePull** or **ImagePullBackOff** so let's look at
the events again:

```bash
$ oc get events --sort-by=.metadata.creationTimestamp --field-selector involvedObject.name=test-pod-2
LAST SEEN   TYPE      REASON           OBJECT           MESSAGE
13s         Normal    Scheduled        pod/test-pod-2   Successfully assigned stf042/test-pod-2 to spoke-marble6.ccs.ornl.gov
11s         Normal    AddedInterface   pod/test-pod-2   Add eth0 [10.35.14.135/23]
11s         Normal    Pulling          pod/test-pod-2   Pulling image "cents:7"
10s         Warning   Failed           pod/test-pod-2   Failed to pull image "cents:7": rpc error: code = Unknown desc = Error reading manifest 7 in docker.io/library/cents: errors:
denied: requested access to the resource is denied
unauthorized: authentication required
10s         Warning   Failed           pod/test-pod-2   Error: ErrImagePull
9s          Normal    BackOff          pod/test-pod-2   Back-off pulling image "cents:7"
9s          Warning   Failed           pod/test-pod-2   Error: ImagePullBackOff
```

We get a much longer sequence of events. First we see that the scheduler was able to assign it to
a node, in this case `spoke-marble6.ccs.ornl.gov`, the networking was plumbed to the container and
the image was being pulled but we hit an error. It looks like our image name is incorrect which is
causing the Pod to enter an **ErrImagePull** state. In this state it will attempt to pull the image
a few more times before giving up and entering a back off period where it will try but with longer
intervals between tries.

```diff
--- pod_image.yaml
+++ pod.yaml
@@ -1,13 +1,13 @@
 apiVersion: v1
 kind: Pod
 metadata:
-  name: test-pod-2
+  name: test-pod-3
   labels:
     tutorial: debugging
 spec:
   containers:
     - name: test-pod
-      image: "cents:7"
+      image: "centos:7"
       command: ["/bin/sh","-c"]
       args: ["echo 'Hello World!'; cat"]
       tty: true
```

We can fix that typo by deleting and creating a new Pod:

```bash
oc delete -f pod_image.yaml
oc apply -f pod.yaml
```

We can see that this Pod is running normally:

```bash
$ oc get pods
NAME         READY   STATUS    RESTARTS   AGE
test-pod-3   1/1     Running   0          43s
```

We can also check the events for the pod to see the final steps of the orchestration that involve
starting the container:

```bash
oc get events --sort-by=.metadata.creationTimestamp --field-selector involvedObject.name=test-pod-3
```

[Next](03_debug.md)
